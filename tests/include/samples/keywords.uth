
/**
 * @file keywords.uth
 *
 * @copyright This file is a part of the project yarac and is distributed under MIT license that
 * should have been included with the project. If not, see https://choosealicense.com/licenses/mit/
 *
 * @author jorib
 *
 * @date 2022-11-30
 */

#ifndef _KEYWORDS_UTH_
#define _KEYWORDS_UTH_

static unsigned long long UT_keywordTokenKinds[] =
{
	TOKEN_KIND_KEYWORD_I8,
	TOKEN_KIND_KEYWORD_I16,
	TOKEN_KIND_KEYWORD_I32,
	TOKEN_KIND_KEYWORD_I64,
	TOKEN_KIND_KEYWORD_U8,
	TOKEN_KIND_KEYWORD_U16,
	TOKEN_KIND_KEYWORD_U32,
	TOKEN_KIND_KEYWORD_U64,
	TOKEN_KIND_KEYWORD_F32,
	TOKEN_KIND_KEYWORD_F64,
	TOKEN_KIND_KEYWORD_P8,
	TOKEN_KIND_KEYWORD_P16,
	TOKEN_KIND_KEYWORD_P32,
	TOKEN_KIND_KEYWORD_P64,
	TOKEN_KIND_KEYWORD_NULL,
	TOKEN_KIND_KEYWORD_IMPORT,
	TOKEN_KIND_KEYWORD_FROM,
	TOKEN_KIND_KEYWORD_MODULE,
	TOKEN_KIND_KEYWORD_EXPORT,
	TOKEN_KIND_KEYWORD_ALIAS,
	TOKEN_KIND_KEYWORD_CONST,
	TOKEN_KIND_KEYWORD_PACKED,
	TOKEN_KIND_KEYWORD_STRUCT,
	TOKEN_KIND_KEYWORD_FIELD,
	TOKEN_KIND_KEYWORD_BYTES,
	TOKEN_KIND_KEYWORD_INLINE,
	TOKEN_KIND_KEYWORD_PROCEDURE,
	TOKEN_KIND_KEYWORD_IN,
	TOKEN_KIND_KEYWORD_OUT,
	TOKEN_KIND_KEYWORD_AS,
	TOKEN_KIND_KEYWORD_RETURN,
	TOKEN_KIND_KEYWORD_IF,
	TOKEN_KIND_KEYWORD_WHILE,
	TOKEN_KIND_KEYWORD_WITH,
	TOKEN_KIND_KEYWORD_DO,
	TOKEN_KIND_KEYWORD_END
};
static_assert((TOKEN_KIND_LAST_KEYWORD - TOKEN_KIND_FIRST_KEYWORD + 1) ==  (sizeof(UT_keywordTokenKinds) / sizeof(unsigned long long)), // Change when types are modified in the compiler!
	"The local `UT_keywordTokenKinds` set is not synced with updated types enum!");

UT_ADD_TEST(keywords,
{
	signed char succeeded = 0;
	struct Vector* tokens = NULL;
	const char* source = SAMPLES_DIR"/keywords.yara";

	W_Vector_create((struct Vector** const)&tokens, 4, &succeeded,
	{
		succeeded = 0;
		return 1;
	},
	{
		W_Logger_log(LOG_KIND_INTERNAL, NO_LOCATION, "%s",
			"failed to create tokens vector!");
		// succeeded = 0;
		return 1;
	},
	{});

	W_Lexer_lexFile(source, &tokens, &succeeded,
	{
		succeeded = 0;
		return 1;
	},
	{
		W_Logger_log(LOG_KIND_INTERNAL, NO_LOCATION,
			"failed to lex file: %s!",
			source);
		// succeeded = 0;
		return 1;
	},
	{});

	const unsigned long long tokensCount = tokens->count;
	UT_ASSERT_TRUE(keywords, tokensCount == (sizeof(UT_keywordTokenKinds) / sizeof(unsigned long long)));

	unsigned long long currentKind = 0;
	for (unsigned long long index = 0; index < tokens->count; ++index)
	{
		struct Token* token = NULL;

		W_Vector_getAt((struct Vector* const * const)&tokens, index, (void** const)&token, &succeeded,
		{
			succeeded = 0;
			return 0;
		},
		{
			// TODO: log!
			// succeeded = 0;
			return 1;
		},
		{});

		UT_ASSERT_TRUE(keywords, token->kind == UT_keywordTokenKinds[currentKind++]);
	}

	for (unsigned long long index = 0; index < tokens->count; ++index)
	{
		struct Token* token = NULL;

		W_Vector_getAt((struct Vector* const * const)&tokens, index, (void** const)&token, &succeeded,
		{
			succeeded = 0;
			return 0;
		},
		{
			// TODO: log!
			// succeeded = 0;
			return 1;
		},
		{});

		W_Token_destroy((const struct Token* const * const)&token, &succeeded,
		{
			succeeded = 0;
		},
		{
			W_Logger_log(LOG_KIND_ERROR, NO_LOCATION,
				"failed to destroy a token!",
				(const char*)source);
			// succeeded = 0;
		},
		{});
	}

	W_Vector_destroy((const struct Vector* const * const)&tokens, &succeeded,
	{
		succeeded = 0;
		return 1;
	},
	{
		W_Logger_log(LOG_KIND_INTERNAL, NO_LOCATION, "%s",
			"failed to destroy vector container!");
		// succeeded = 0;
		return 1;
	},
	{});
});

#endif
